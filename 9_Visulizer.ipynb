{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb384e-713b-4821-810f-57f901861cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalesDataAnalyzer initialized.\n",
      "Using existing synthetic data file: synthetic_sales_data.csv\n",
      "\n",
      "==================================================\n",
      "       Sales Data Analysis & Visualization Program\n",
      "==================================================\n",
      "Please select an option:\n",
      "1. Load Dataset\n",
      "2. Explore Data (Head, Info, Describe)\n",
      "3. Clean Data (Handle Missing Values)\n",
      "4. Data Manipulation (Math Ops, Numpy, Search, Sort, Filter)\n",
      "5. Aggregate and Statistical Analysis\n",
      "6. Generate Pivot Table\n",
      "7. Data Visualization (Matplotlib & Seaborn)\n",
      "8. Save a Visualization to File\n",
      "9. Exit\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#### import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os # For saving files\n",
    "\n",
    "# Set Matplotlib style for better aesthetics\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "# Configure Seaborn plots to be inline\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Helper function to generate a synthetic sales dataset (required for a runnable example)\n",
    "def generate_synthetic_data(file_path=\"synthetic_sales_data.csv\"):\n",
    "    \"\"\"Generates a synthetic sales dataset and saves it to a CSV file.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Using existing synthetic data file: {file_path}\")\n",
    "        return file_path\n",
    "        \n",
    "    print(\"Generating new synthetic sales data...\")\n",
    "    num_records = 500\n",
    "    \n",
    "    # 1. Date\n",
    "    dates = pd.date_range(start=\"2024-01-01\", periods=num_records, freq='D')\n",
    "    \n",
    "    # 2. Product\n",
    "    products = ['Laptop', 'Smartphone', 'Tablet', 'Accessory']\n",
    "    product_data = np.random.choice(products, size=num_records, p=[0.35, 0.30, 0.20, 0.15])\n",
    "    \n",
    "    # 3. Region\n",
    "    regions = ['East', 'West', 'North', 'South']\n",
    "    region_data = np.random.choice(regions, size=num_records)\n",
    "    \n",
    "    # 4. Sales (Revenue)\n",
    "    sales = np.random.randint(100, 5000, size=num_records) + np.random.randn(num_records) * 50\n",
    "    sales[sales < 100] = 100 # Minimum sales value\n",
    "    \n",
    "    # 5. Profit (calculated as a percentage of sales, with some randomness)\n",
    "    profit_ratios = np.random.uniform(0.1, 0.4, size=num_records) \n",
    "    profit = sales * profit_ratios\n",
    "    \n",
    "    # Introduce some missing values randomly for cleaning demonstration\n",
    "    sales[np.random.choice(num_records, size=20, replace=False)] = np.nan\n",
    "    profit[np.random.choice(num_records, size=15, replace=False)] = np.nan\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'Date': dates[:num_records],\n",
    "        'Product': product_data,\n",
    "        'Region': region_data,\n",
    "        'Sales': sales.astype(float),\n",
    "        'Profit': profit.astype(float)\n",
    "    })\n",
    "    \n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Synthetic data saved to {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# ====================================================================\n",
    "# SalesDataAnalyzer Class (OOP Core)\n",
    "# ====================================================================\n",
    "\n",
    "class SalesDataAnalyzer:\n",
    "    \"\"\"\n",
    "    A comprehensive class for analyzing and visualizing sales data \n",
    "    using Pandas, Matplotlib, and Seaborn.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path=None):\n",
    "        \"\"\"Constructor: Initializes the DataFrame attribute.\"\"\"\n",
    "        self.data = pd.DataFrame()\n",
    "        print(\"SalesDataAnalyzer initialized.\")\n",
    "        if file_path:\n",
    "            self.load_data(file_path)\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Destructor: Simple cleanup message.\"\"\"\n",
    "        # For typical Pandas operations, no explicit cleanup is strictly needed, \n",
    "        # but this fulfills the requirement.\n",
    "        print(\"SalesDataAnalyzer object destroyed.\")\n",
    "        \n",
    "    # --- Data Acquisition & Loading ---\n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load data from a CSV file.\"\"\"\n",
    "        try:\n",
    "            self.data = pd.read_csv(file_path)\n",
    "            # Ensure Date column is in datetime format\n",
    "            self.data['Date'] = pd.to_datetime(self.data['Date'])\n",
    "            print(f\"\\n Dataset loaded successfully from: **{file_path}**\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"\\n  Error: File not found at {file_path}\")\n",
    "            self.data = pd.DataFrame() # Clear data on failure\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"\\n  An error occurred during file loading: {e}\")\n",
    "            self.data = pd.DataFrame()\n",
    "            return False\n",
    "\n",
    "    # --- Data Exploration & Cleaning ---\n",
    "    def explore_data(self):\n",
    "        \"\"\"Display basic information about the dataset.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Basic Data Exploration ---\")\n",
    "        print(\"--- Head (First 5 Rows) ---\")\n",
    "        print(self.data.head())\n",
    "        print(\"\\n--- DataFrame Info (Dtypes, Non-Null Counts) ---\")\n",
    "        self.data.info(verbose=False, buf=None, max_cols=200, memory_usage=True)\n",
    "        print(\"\\n--- Descriptive Statistics (Numerical Columns) ---\")\n",
    "        print(self.data.describe())\n",
    "        print(\"\\n--- Check for Missing Values (NaN) ---\")\n",
    "        print(self.data.isnull().sum())\n",
    "    \n",
    "    def clean_data(self, method='median'):\n",
    "        \"\"\"Handle missing values and perform basic data cleaning.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "            \n",
    "        initial_missing = self.data.isnull().sum().sum()\n",
    "        if initial_missing == 0:\n",
    "            print(\" Data is already clean (no missing values found).\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- Data Cleaning: Handling {initial_missing} missing values ---\")\n",
    "\n",
    "        # 1. Handle Missing Numerical Values ('Sales', 'Profit')\n",
    "        for col in ['Sales', 'Profit']:\n",
    "            if self.data[col].isnull().any():\n",
    "                if method == 'median':\n",
    "                    fill_value = self.data[col].median()\n",
    "                    self.data[col].fillna(fill_value, inplace=True)\n",
    "                    print(f\"   Filled missing values in '{col}' with the **median** ({fill_value:.2f}).\")\n",
    "                elif method == 'mean':\n",
    "                    fill_value = self.data[col].mean()\n",
    "                    self.data[col].fillna(fill_value, inplace=True)\n",
    "                    print(f\"   Filled missing values in '{col}' with the **mean** ({fill_value:.2f}).\")\n",
    "                else: # Default to dropping for simplicity if method is unknown\n",
    "                    self.data.dropna(subset=[col], inplace=True)\n",
    "                    print(f\"   Dropped rows with missing values in '{col}'.\")\n",
    "\n",
    "        # 2. Handle Missing Categorical Values ('Product', 'Region') - assuming simple drop or mode fill\n",
    "        for col in ['Product', 'Region']:\n",
    "             if self.data[col].isnull().any():\n",
    "                 # Fill with mode (most frequent)\n",
    "                 fill_value = self.data[col].mode()[0]\n",
    "                 self.data[col].fillna(fill_value, inplace=True)\n",
    "                 print(f\"   Filled missing values in '{col}' with the **mode** ({fill_value}).\")\n",
    "\n",
    "        final_missing = self.data.isnull().sum().sum()\n",
    "        print(f\" Cleaning complete. Total missing values remaining: {final_missing}\")\n",
    "\n",
    "    # --- Data Manipulation (Pandas/Numpy) ---\n",
    "\n",
    "    def mathematical_operations(self):\n",
    "        \"\"\"Perform mathematical operations on data and demonstrate Numpy arrays.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Mathematical Operations & Numpy Demonstration ---\")\n",
    "        \n",
    "        # New Column Creation (Element-wise operation)\n",
    "        self.data['Tax_Amount'] = self.data['Sales'] * 0.05 # 5% tax\n",
    "        print(\" New column 'Tax_Amount' (Sales * 0.05) created.\")\n",
    "        \n",
    "        # Numpy Array Creation and Operations (Requirement A & B)\n",
    "        sales_np = self.data['Sales'].to_numpy() # Convert to Numpy array\n",
    "        \n",
    "        # Indexing and Slicing (Requirement A)\n",
    "        print(f\"\\nNumpy Array Indexing: sales_np[0] = {sales_np[0]:.2f}\")\n",
    "        print(f\"Numpy Array Slicing: sales_np[1:4] = {sales_np[1:4].round(2)}\")\n",
    "        \n",
    "        # Element-wise Mathematical Operation (Requirement B)\n",
    "        discounted_sales_np = sales_np * 0.95 \n",
    "        print(f\"Element-wise math: First 3 discounted sales (0.95 * Sales) = {discounted_sales_np[:3].round(2)}\")\n",
    "\n",
    "    def combine_data(self, other_dataframe):\n",
    "        \"\"\"Combine current DataFrame with another using concat.\"\"\"\n",
    "        if self.data.empty or other_dataframe.empty:\n",
    "            print(\" Cannot combine: one or both DataFrames are empty.\")\n",
    "            return\n",
    "\n",
    "        initial_rows = len(self.data)\n",
    "        # Using concat to combine data (assuming similar columns)\n",
    "        self.data = pd.concat([self.data, other_dataframe], ignore_index=True)\n",
    "        print(f\" DataFrames combined using **pd.concat()**. Rows added: {len(self.data) - initial_rows}\")\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Split DataFrame into multiple DataFrames based on 'Region'.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Data Splitting by 'Region' ---\")\n",
    "        regions = self.data['Region'].unique()\n",
    "        split_dfs = {}\n",
    "        for region in regions:\n",
    "            # Split using boolean filtering\n",
    "            split_dfs[region] = self.data[self.data['Region'] == region].copy()\n",
    "            print(f\"   Created DataFrame for **{region}**: {len(split_dfs[region])} rows.\")\n",
    "            \n",
    "        print(\" DataFrame successfully split into multiple regional DataFrames.\")\n",
    "        return split_dfs\n",
    "\n",
    "    # --- Data Analysis (Search, Sort, Filter, Aggregate, Statistical) ---\n",
    "\n",
    "    def search_sort_filter(self):\n",
    "        \"\"\"Implement search, sort, and filter functionalities.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Search, Sort, and Filter Operations ---\")\n",
    "        \n",
    "        # 1. Search (Requirement C)\n",
    "        # Search for products with Sales > $4000\n",
    "        high_sales_products = self.data[self.data['Sales'] > 4000]\n",
    "        print(f\"\\n Search: Found **{len(high_sales_products)}** records with Sales > $4000.\")\n",
    "        if not high_sales_products.empty:\n",
    "            print(f\"   Example: {high_sales_products.iloc[0]['Product']} in {high_sales_products.iloc[0]['Region']} on {high_sales_products.iloc[0]['Date'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # 2. Filter (Requirement C)\n",
    "        # Filter for 'West' region and 'Laptop' product\n",
    "        filtered_data = self.data[(self.data['Region'] == 'West') & (self.data['Product'] == 'Laptop')]\n",
    "        print(f\"\\n🧹 Filter: Found **{len(filtered_data)}** records for 'Laptop' in 'West' region.\")\n",
    "        \n",
    "        # 3. Sort (Requirement C)\n",
    "        sorted_data = self.data.sort_values(by='Profit', ascending=False)\n",
    "        print(\"\\n Sort: Data sorted by 'Profit' (Descending). Top 3 by Profit:\")\n",
    "        print(sorted_data[['Date', 'Product', 'Profit']].head(3))\n",
    "        \n",
    "    def aggregate_functions(self):\n",
    "        \"\"\"Apply aggregating functions like sum, mean, etc.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Aggregating Functions (sum, mean, count) ---\")\n",
    "        \n",
    "        # Group by 'Region' and aggregate Sales/Profit\n",
    "        regional_summary = self.data.groupby('Region').agg(\n",
    "            Total_Sales=('Sales', 'sum'),\n",
    "            Average_Profit=('Profit', 'mean'),\n",
    "            Count_Records=('Product', 'count')\n",
    "        ).round(2)\n",
    "        \n",
    "        print(\"\\nTotal Sales, Average Profit, and Count by Region:\")\n",
    "        print(regional_summary)\n",
    "        print(\" Aggregation complete.\")\n",
    "\n",
    "    def statistical_analysis(self):\n",
    "        \"\"\"Perform statistical computations (std, var, quantile, describe).\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Statistical Analysis (Std Dev, Variance, Quantile) ---\")\n",
    "        \n",
    "        # Use describe() (Requirement D)\n",
    "        print(\"\\nFull Descriptive Statistics for Sales and Profit:\")\n",
    "        print(self.data[['Sales', 'Profit']].describe().T) # Transpose for better view\n",
    "\n",
    "        # Calculate specific statistics (Requirement D)\n",
    "        sales_std = self.data['Sales'].std()\n",
    "        sales_var = self.data['Sales'].var()\n",
    "        profit_p90 = self.data['Profit'].quantile(0.90) # 90th percentile\n",
    "        \n",
    "        print(f\"\\n Sales Standard Deviation (std()): **${sales_std:,.2f}**\")\n",
    "        print(f\" Sales Variance (var()): **${sales_var:,.2f}**\")\n",
    "        print(f\" 90th Percentile of Profit (quantile(0.9)): **${profit_p90:,.2f}**\")\n",
    "        \n",
    "    def create_pivot_table(self):\n",
    "        \"\"\"Generate pivot tables for data summarization.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Pivot Table Creation ---\")\n",
    "        \n",
    "        # Pivot table: Total Sales by Region and Product\n",
    "        pivot_sales = self.data.pivot_table(\n",
    "            index='Region', \n",
    "            columns='Product', \n",
    "            values='Sales', \n",
    "            aggfunc='sum', \n",
    "            fill_value=0 # Replace NaN with 0\n",
    "        ).round(2)\n",
    "        \n",
    "        print(\"\\nTotal Sales (Sum) by Region and Product:\")\n",
    "        print(pivot_sales)\n",
    "        print(\" Pivot table generated.\")\n",
    "\n",
    "    # --- Data Visualization (Matplotlib & Seaborn) ---\n",
    "    def visualize_data(self):\n",
    "        \"\"\"Create various plots using Matplotlib and Seaborn (Requirements E & F).\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- Data Visualization ---\")\n",
    "        \n",
    "        # Ensure the 'Date' is set as the index for time-series plots\n",
    "        daily_sales = self.data.set_index('Date').resample('M')['Sales'].sum() # Monthly sales\n",
    "        \n",
    "        # =========================================================\n",
    "        # Matplotlib Plots (Requirement E)\n",
    "        # =========================================================\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(18, 15)) # Create subplots\n",
    "        fig.suptitle('Matplotlib Sales Analysis Visualizations', fontsize=20, y=1.02)\n",
    "        \n",
    "        # 1. Line Plot (E) - Monthly Sales Trend\n",
    "        daily_sales.plot(kind='line', ax=axes[0, 0], title='Monthly Sales Trend (Line Plot)', color='b')\n",
    "        axes[0, 0].set_ylabel('Total Sales ($)')\n",
    "        axes[0, 0].legend(['Sales'])\n",
    "        \n",
    "        # 2. Bar Plot (E) - Total Sales by Region\n",
    "        region_sales = self.data.groupby('Region')['Sales'].sum()\n",
    "        region_sales.plot(kind='bar', ax=axes[0, 1], title='Total Sales by Region (Bar Plot)', color='skyblue')\n",
    "        axes[0, 1].set_ylabel('Total Sales ($)')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=0) # Remove tilt\n",
    "        \n",
    "        # 3. Scatter Plot (E) - Sales vs. Profit\n",
    "        axes[1, 0].scatter(self.data['Sales'], self.data['Profit'], alpha=0.6, color='g')\n",
    "        axes[1, 0].set_title('Sales vs. Profit (Scatter Plot)')\n",
    "        axes[1, 0].set_xlabel('Sales ($)')\n",
    "        axes[1, 0].set_ylabel('Profit ($)')\n",
    "        \n",
    "        # 4. Histogram (E) - Distribution of Profit\n",
    "        axes[1, 1].hist(self.data['Profit'], bins=20, color='coral', edgecolor='black')\n",
    "        axes[1, 1].set_title('Profit Distribution (Histogram)')\n",
    "        axes[1, 1].set_xlabel('Profit ($)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "        # 5. Pie Plot (E) - Product Distribution\n",
    "        product_counts = self.data['Product'].value_counts()\n",
    "        product_counts.plot(kind='pie', ax=axes[2, 0], autopct='%1.1f%%', startangle=90, title='Product Count Distribution (Pie Plot)', ylabel='')\n",
    "        axes[2, 0].legend(title=\"Products\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "        # 6. Stack Plot (E) - Total Sales over time, stacked by Region (simplified for sample data)\n",
    "        # NOTE: Stack plots require wide data. A simpler demonstration:\n",
    "        data_pivot = self.data.set_index('Date').groupby('Region')['Sales'].resample('M').sum().unstack(level=0, fill_value=0)\n",
    "        num_regions = len(data_pivot.columns)\n",
    "        # Use the colormap as a function to generate a list of colors\n",
    "        colors = plt.cm.coolwarm(np.linspace(0, 1, num_regions)) \n",
    "        \n",
    "        axes[2, 1].stackplot(data_pivot.index, data_pivot.values.T, labels=data_pivot.columns, colors=colors)\n",
    "        # ------------------------\n",
    "\n",
    "        axes[2, 1].set_title('Monthly Sales by Region (Stack Plot)')\n",
    "        axes[2, 1].set_xlabel('Date')\n",
    "        axes[2, 1].set_ylabel('Total Sales ($)')\n",
    "        axes[2, 1].legend(loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show() # Display Matplotlib plots\n",
    "\n",
    "        # =========================================================\n",
    "        # Seaborn Plots (Requirement F)\n",
    "        # =========================================================\n",
    "        \n",
    "        # Create a new figure for Seaborn plots\n",
    "        plt.figure(figsize=(15, 6))\n",
    "\n",
    "        # 7. Box Plot (F) - Sales Distribution by Product\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.boxplot(x='Product', y='Sales', data=self.data, palette='viridis')\n",
    "        plt.title('Sales Distribution by Product (Seaborn Box Plot)')\n",
    "        \n",
    "        # 8. Heatmap (F) - Correlation Matrix\n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = self.data[['Sales', 'Profit', 'Tax_Amount']].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, linecolor='black')\n",
    "        plt.title('Correlation Heatmap (Seaborn)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show() # Display Seaborn plots\n",
    "        print(\" Visualizations generated using Matplotlib and Seaborn.\")\n",
    "        \n",
    "    def save_visualization(self, plot_name, file_format='png'):\n",
    "        \"\"\"Saves a simple Bar Plot of Regional Sales as an image file.\"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\" Load data first.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            region_sales = self.data.groupby('Region')['Sales'].sum()\n",
    "            region_sales.plot(kind='bar', color='darkblue')\n",
    "            plt.title('Total Sales by Region')\n",
    "            plt.ylabel('Total Sales ($)')\n",
    "            plt.xlabel('Region')\n",
    "            plt.tick_params(axis='x', rotation=0)\n",
    "            \n",
    "            filename = f\"{plot_name}.{file_format}\"\n",
    "            plt.savefig(filename)\n",
    "            plt.close() # Close the figure to free memory\n",
    "            print(f\" Visualization saved successfully as: **{filename}**\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error saving visualization: {e}\")\n",
    "\n",
    "# ====================================================================\n",
    "# Main Program & Menu-Driven Interface (UI Core)\n",
    "# ====================================================================\n",
    "\n",
    "def display_menu():\n",
    "    \"\"\"Displays the main menu options.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"       Sales Data Analysis & Visualization Program\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Please select an option:\")\n",
    "    print(\"1. Load Dataset\")\n",
    "    print(\"2. Explore Data (Head, Info, Describe)\")\n",
    "    print(\"3. Clean Data (Handle Missing Values)\")\n",
    "    print(\"4. Data Manipulation (Math Ops, Numpy, Search, Sort, Filter)\")\n",
    "    print(\"5. Aggregate and Statistical Analysis\")\n",
    "    print(\"6. Generate Pivot Table\")\n",
    "    print(\"7. Data Visualization (Matplotlib & Seaborn)\")\n",
    "    print(\"8. Save a Visualization to File\")\n",
    "    print(\"9. Exit\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the menu-driven interface.\"\"\"\n",
    "    \n",
    "    # 1. Initialization and Data Generation\n",
    "    sales_analyzer = SalesDataAnalyzer()\n",
    "    \n",
    "    # Generate synthetic data path (for a runnable example)\n",
    "    data_file_path = generate_synthetic_data() \n",
    "    \n",
    "    while True:\n",
    "        display_menu()\n",
    "        \n",
    "        try:\n",
    "            choice = input(\"Enter your choice: \").strip()\n",
    "            \n",
    "            if choice == '1':\n",
    "                # Load Dataset\n",
    "                file_path = input(f\"Enter the path of the dataset (CSV file), e.g., **{data_file_path}**: \")\n",
    "                sales_analyzer.load_data(file_path)\n",
    "            \n",
    "            elif choice == '2':\n",
    "                # Explore Data\n",
    "                sales_analyzer.explore_data()\n",
    "            \n",
    "            elif choice == '3':\n",
    "                # Clean Data\n",
    "                sales_analyzer.clean_data()\n",
    "            \n",
    "            elif choice == '4':\n",
    "                # Data Manipulation (A, B, C part 1)\n",
    "                sales_analyzer.mathematical_operations()\n",
    "                # Demonstration of Search, Sort, Filter\n",
    "                sales_analyzer.search_sort_filter()\n",
    "                # Demonstrating combining and splitting (needs extra step)\n",
    "                # sales_analyzer.split_data() # Returns dict of split DFs\n",
    "                # print(\"\\nData Splitting and Combining methods are also available as class methods.\")\n",
    "            \n",
    "            elif choice == '5':\n",
    "                # Aggregate and Statistical Analysis (C part 2, D)\n",
    "                sales_analyzer.aggregate_functions()\n",
    "                sales_analyzer.statistical_analysis()\n",
    "\n",
    "            elif choice == '6':\n",
    "                # Generate Pivot Table\n",
    "                sales_analyzer.create_pivot_table()\n",
    "\n",
    "            elif choice == '7':\n",
    "                # Data Visualization (E, F)\n",
    "                sales_analyzer.visualize_data()\n",
    "            \n",
    "            elif choice == '8':\n",
    "                # Save Visualization\n",
    "                plot_name = input(\"Enter the desired file name (e.g., regional_sales_report): \")\n",
    "                sales_analyzer.save_visualization(plot_name)\n",
    "\n",
    "            elif choice == '9':\n",
    "                # Exit Program\n",
    "                print(\"\\nExiting Program. Thank you for using the Sales Data Analyzer! 👋\")\n",
    "                # Explicitly deleting the object to show the __del__ destructor\n",
    "                del sales_analyzer \n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                print(\"  Invalid choice. Please select an option from 1 to 9.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n An unexpected error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dda4a-8959-45cc-9dc4-1a8f47da73ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
